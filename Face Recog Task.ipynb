{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-f57edfd2289b>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# CREATING TRAINING DATASET\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "#TRAIN MODEL\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "alok_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "alok_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_whatsmsg():\n",
    "    import pywhatkit\n",
    "    hours = int(input(\"Input Hour : \"))\n",
    "    mins = int(input(\"Input Minutes : \"))\n",
    "    pywhatkit.sendwhatmsg('+917488843214','Hello there!',hours,mins, wait_time=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_mail():\n",
    "    import smtplib\n",
    "    sender = \"alokjsme28@gmail.com\"\n",
    "    receiver = \"deepakjsme20@gmail.com\"\n",
    "    message = \"\"\"From: From Alok <alokjsme28@gmail.com>\n",
    "    To: To Deepak <deepakjsme20@gmail.com>\n",
    "    Subject: Face Recognition.\n",
    "\n",
    "    This is the face of Alok.\n",
    "    \"\"\"\n",
    "    try : \n",
    "        s = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "        s.login(\"alokjsme28@gmail.com\", \"tzmdakhxeurxglon\")\n",
    "        s.sendmail(sender,receiver,message)\n",
    "        print(\"Mail Sent Successfully ..\")\n",
    "    except SMTPException :\n",
    "        print(\"Error sending the mail !!\")\n",
    "    s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "def aws_ec2():\n",
    "    global ins_id\n",
    "    global vol_id\n",
    "    aws_ec2 = boto3.resource(\"ec2\")\n",
    "    \n",
    "    #Starting Instance\n",
    "    os.system(\"aws ec2 run-instances --image-id  ami-0ad704c126371a549  --instance-type  t2.micro --security-group-ids  sg-fd7f7687  --count  1  --subnet-id  subnet-e3aa4588 --key-name  alok  --tag-specifications ResourceType=instance,Tags=[{Key=Name,Value=alok-ami}] \")\n",
    "    \n",
    "    #Creating Volume\n",
    "    os.system(\"aws ec2 create-volume  --availability-zone  ap-south-1a  --size 5  --tag-specifications ResourceType=volume,Tags=[{Key=Name,Value=ebs-volume}]\")\n",
    "    \n",
    "    print(\"Available Instances :\")          \n",
    "    for instance in aws_ec2.instances.all():\n",
    "        #Fetching instance_id\n",
    "        print(\"Id: {0}\\nPublic IPv4: {1}\\n State: {2}\\n\".format(instance.id,instance.public_ip_address,instance.state))\n",
    "            \n",
    "    print(\"Available Volumes : \\n\")\n",
    "    for vol in aws_ec2.volumes.all():\n",
    "        #Fetching volume_id\n",
    "        print(vol.id,\"\\t\", vol.volume_type, \"\\t\", vol.size,\"GiB\",\"\\t\", vol.state)      \n",
    "    \n",
    "    input()\n",
    "    \n",
    "    for i in aws_ec2.instances.all():    \n",
    "        if i.state['Name']=='running':\n",
    "            ins_id = i.id\n",
    "            print(ins_id)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    for v in aws_ec2.volumes.all():    \n",
    "        if v.state == 'available':\n",
    "            vol_id = v.id\n",
    "            print(vol_id)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    output = sp.getstatusoutput(f\"aws ec2 attach-volume --volume-id {vol_id} --instance-id {ins_id} --device /dev/sdf\")\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-7-1ae5c2c0b953>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Instances :\n",
      "Id: i-09e4b98b09a212d79\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-058825bb3c7ad0317\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-0dbdb2e201e25b6fd\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-08e2c9426531bf976\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-0311e4fc426747d02\n",
      "Public IPv4: 35.154.250.11\n",
      " State: {'Code': 0, 'Name': 'pending'}\n",
      "\n",
      "Available Volumes : \n",
      "\n",
      "vol-06fbbabbbbb1a3b99 \t gp2 \t 8 GiB \t in-use\n",
      "vol-0138ad9ffb5b55cee \t gp2 \t 5 GiB \t creating\n",
      "\n",
      "vol-0138ad9ffb5b55cee\n",
      "Available Instances :\n",
      "Id: i-09e4b98b09a212d79\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-058825bb3c7ad0317\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-0dbdb2e201e25b6fd\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-08e2c9426531bf976\n",
      "Public IPv4: None\n",
      " State: {'Code': 48, 'Name': 'terminated'}\n",
      "\n",
      "Id: i-02fd103d2f77aecdf\n",
      "Public IPv4: 65.2.9.24\n",
      " State: {'Code': 0, 'Name': 'pending'}\n",
      "\n",
      "Id: i-0311e4fc426747d02\n",
      "Public IPv4: 35.154.250.11\n",
      " State: {'Code': 16, 'Name': 'running'}\n",
      "\n",
      "Available Volumes : \n",
      "\n",
      "vol-06fbbabbbbb1a3b99 \t gp2 \t 8 GiB \t in-use\n",
      "vol-0138ad9ffb5b55cee \t gp2 \t 5 GiB \t available\n",
      "vol-0862ca9d37b378324 \t gp2 \t 8 GiB \t in-use\n",
      "vol-06a38317a046fdc8f \t gp2 \t 5 GiB \t creating\n",
      "\n",
      "i-0311e4fc426747d02\n",
      "vol-0138ad9ffb5b55cee\n",
      "vol-06a38317a046fdc8f\n",
      "(0, '{\\n    \"AttachTime\": \"2021-06-17T12:36:39.306000+00:00\",\\n    \"Device\": \"/dev/sdf\",\\n    \"InstanceId\": \"i-0311e4fc426747d02\",\\n    \"State\": \"attaching\",\\n    \"VolumeId\": \"vol-06a38317a046fdc8f\"\\n}')\n"
     ]
    }
   ],
   "source": [
    "#RUN FACIAL RECOGNITION\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = alok_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 90:\n",
    "            cv2.putText(image, \"Hey Alok\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            send_mail()\n",
    "            send_whatsmsg()\n",
    "            break\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"Oops, I don't recognize you\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            aws_ec2()\n",
    "            break\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
